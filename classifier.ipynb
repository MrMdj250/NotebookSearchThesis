{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Search, Q\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "#from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown + comments 1\n",
    "code 0.4\n",
    "simpele 0.3\n",
    "score = [s1,s2,s3]\n",
    "dot weights\n",
    "query en ding cosine similarity\n",
    "vector cosine similarity new gewogen score\n",
    "Lineaire combinatie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to local elastic search host\n",
    "HOST = 'http://localhost:9200/'\n",
    "es = Elasticsearch(hosts=[HOST], timeout=30) # , max_retries=10, retry_on_timeout=True\n",
    "INDEX2 = 'info_clone2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "s = Search(using=es, index=INDEX2)\n",
    "q = Q(\"wildcard\", name='*')\n",
    "query = s.query(q).extra(size=10000)\n",
    "response = query.execute()\n",
    "print(len(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ids\n",
    "ids = []\n",
    "for res in response:\n",
    "    nid = res.meta.id\n",
    "    ids.append(nid)\n",
    "\n",
    "# get the code and markdown samples\n",
    "Xy = []\n",
    "for i in ids:\n",
    "    c = es.get(index=\"code\", id=i)\n",
    "    code = c['_source']['code']\n",
    "    m = es.get(index=\"markdown\", id=i)\n",
    "    markdown = m['_source']['markdown']\n",
    "    if code != [] and markdown != []:\n",
    "        Xy.append((i, ''.join(code), 'code'))\n",
    "        Xy.append((i, ''.join(markdown), 'markdown'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xydf = pd.DataFrame(Xy, columns=('id','sample','label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sample</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>479522</td>\n",
       "      <td># requirement : 1 = must visit; 0 = must not v...</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>479522</td>\n",
       "      <td>### CS/ECE/ISyE 524 &amp;mdash; Introduction to Op...</td>\n",
       "      <td>markdown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>581536</td>\n",
       "      <td>!sudo pip install geocoderimport geocoderloc =...</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>581536</td>\n",
       "      <td># Geocoding\\n\\n* Converting a plain text addre...</td>\n",
       "      <td>markdown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400611</td>\n",
       "      <td># Import Numpy, TensorFlow, TFLearn, and MNIST...</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13715</th>\n",
       "      <td>475366</td>\n",
       "      <td>__N.B.,__ Cannot use 32-bit programmable inter...</td>\n",
       "      <td>markdown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13716</th>\n",
       "      <td>435782</td>\n",
       "      <td>import sympy as sp\\nimport numpy as np\\nimport...</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13717</th>\n",
       "      <td>435782</td>\n",
       "      <td># Integration using libraries, and flow plots\\...</td>\n",
       "      <td>markdown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13718</th>\n",
       "      <td>518507</td>\n",
       "      <td>from math import pi,sqrt\\nfrom __future__ impo...</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13719</th>\n",
       "      <td>518507</td>\n",
       "      <td># Chapter 2 Diode Applications## Exa 2.1 page ...</td>\n",
       "      <td>markdown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13720 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                             sample     label\n",
       "0      479522  # requirement : 1 = must visit; 0 = must not v...      code\n",
       "1      479522  ### CS/ECE/ISyE 524 &mdash; Introduction to Op...  markdown\n",
       "2      581536  !sudo pip install geocoderimport geocoderloc =...      code\n",
       "3      581536  # Geocoding\\n\\n* Converting a plain text addre...  markdown\n",
       "4      400611  # Import Numpy, TensorFlow, TFLearn, and MNIST...      code\n",
       "...       ...                                                ...       ...\n",
       "13715  475366  __N.B.,__ Cannot use 32-bit programmable inter...  markdown\n",
       "13716  435782  import sympy as sp\\nimport numpy as np\\nimport...      code\n",
       "13717  435782  # Integration using libraries, and flow plots\\...  markdown\n",
       "13718  518507  from math import pi,sqrt\\nfrom __future__ impo...      code\n",
       "13719  518507  # Chapter 2 Diode Applications## Exa 2.1 page ...  markdown\n",
       "\n",
       "[13720 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(Xydf['sample'][0], str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate TF-IDF values\n",
    "def get_features(df,field,train_data,test_data):\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_df=0.95)\n",
    "    tfidf_vectorizer.fit_transform(train_data[field].values)\n",
    "\n",
    "    train_feature_set = tfidf_vectorizer.transform(train_data[field].values)\n",
    "    test_feature_set = tfidf_vectorizer.transform(test_data[field].values)\n",
    "\n",
    "    return train_feature_set,test_feature_set,tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a training and test set, seed for same result\n",
    "train_data, test_data = train_test_split(Xydf,random_state = 2000)\n",
    " \n",
    "# get the training and test set labels \n",
    "Y_train = train_data['label'].values\n",
    "Y_test = test_data['label'].values\n",
    "     \n",
    "# get the features\n",
    "X_train,X_test,feat_trans = get_features(Xydf,'sample',train_data,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2))\n",
    "clf = LogisticRegression(random_state=0)\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'model.pkl'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9603498542274053\n"
     ]
    }
   ],
   "source": [
    "# load the model from disk\n",
    "filename = 'model.pkl'\n",
    "clf = pickle.load(open(filename, 'rb'))\n",
    "score = clf.score(X_test, Y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a random document\n",
    "t = es.search(index=\"code\", body={\"size\": 1, \"query\": {\"function_score\": {\"random_score\": {\"seed\": 10}}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab\n",
      "import astropy.io.fits as pf\n",
      "import pyqtgraph as pqrun /Users/aaronresnick/Desktop/CODERepository/pteropractice/winview_v02.pyflist = loadtxt('/Users/aaronresnick/Desktop/CODERepository/Doc_calibrations/flist.txt',dtype='str')flistlist = []for i in range(len(flist)):\n",
      "     list.append(load_spe('/Users/aaronresnick/Desktop/CODERepository/Doc_calibrations/'+flist[i]))dark_1us = load_spe('/Users/aaronresnick/Desktop/CODERepository/Doc_calibrations/20150618_2.SPE')dark_1us.shapesuperdark = mean(dark_1us, axis=0)superdark.shapeimshow(superdark)plot(superdark[300,:])dark_2s = load_spe('/Users/aaronresnick/Desktop/CODERepository/Doc_calibrations/20150618_5.SPE')superdark2 = mean(dark_2s,axis = 0)imshow(superdark2)figure(2)\n",
      "plot(superdark2[300,:])figure(3)\n",
      "plot(superdark[300,:])oneSeccube = list[5]secMed = median(oneSeccube)secMedsecMicro = median(dark_1us)secMicrosec2s = median(dark_2s)sec2smilSec = list[4]milSecMed = median(milSec)milSecMedkey = array((1.0e-6,1.0e-3,1.0,2.0))meds = array((secMicro,milSecMed,secMed,sec2s))clf()\n",
      "plot(key,meds)\n"
     ]
    }
   ],
   "source": [
    "sample = t['hits']['hits'][0]['_source']['code']\n",
    "sample = ''.join(sample)\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample2 = sample\n",
    "sampletrans = feat_trans.transform([sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['code'], dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(sampletrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
