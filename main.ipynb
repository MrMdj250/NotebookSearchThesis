{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main\n",
    "Michael de Jong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import json\n",
    "from elasticsearch import Elasticsearch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nbconvert\n",
    "import nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load local python file(s)\n",
    "%run evaluationmetrics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n",
      "0.75\n",
      "0.4285714285714285\n",
      "0.262359022556391\n"
     ]
    }
   ],
   "source": [
    "# 1 = relevant, 0 = not relevant\n",
    "l = [1,1,0,0,0,0,0,0,1,0,1,0,0,0,1,0,0,0,0,1]\n",
    "c = 8\n",
    "print(precision(l))\n",
    "print(recall(l,c))\n",
    "print(f1(l,c))\n",
    "print(avg_precision(l,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_precision([1,1],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to local elastic search host\n",
    "HOST = 'http://localhost:9200/'\n",
    "es = Elasticsearch(hosts=[HOST])\n",
    "\n",
    "INDEX=\"wikidataframe\"\n",
    "TYPE= \"doc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from lxml import etree\n",
      "from lxml import objectify\n",
      "import pandas as pd\n",
      "import re as re\n",
      "from sqlalchemy import create_engine\n",
      "from subprocess import Popen\n",
      "#import lxml.usedoctest from http://lxml.de/objectify.html\n",
      "p_out_sql_cat='Cat'\n",
      "p_out_sql_id='VarID'\n",
      "p_out_sql_answer='AnswerLabel'\n",
      "p_out_sql_lists='Lists'\n",
      "path_mdd=r'\\\\TSHAMFIL901\\Work\\DV\\MatthiasH\\BBG_Tracking'.replace(chr(92),'/')\n",
      "file_mdd=path_mdd+'/'+'data.mdd'\n",
      "\n",
      "pfad_out=r'\\\\TSHAMFIL901\\Work\\DV\\MatthiasH\\BBG_Tracking\\out'.replace(chr(92),'/')\n",
      "file_cat_out_csv=pfad_out+'/'+p_out_sql_cat+'.csv'\n",
      "file_id_out_csv=pfad_out+'/'+p_out_sql_id+'.csv'\n",
      "file_answer_out_csv=pfad_out+'/'+p_out_sql_answer+'.csv'\n",
      "file_lists_out_csv=pfad_out+'/'+p_out_sql_lists+'.csv'\n",
      "\n",
      "\n",
      "path_bat=r'\\\\TSHAMFIL901\\Work\\DV\\MatthiasH\\BBG_Tracking\\out'+chr(92)\n",
      "file_bat=path_bat+'/'+'bbg_csv.bat'\n",
      "p_mode='r' # r=replace, a = append\n",
      "engine_dv_bbg = create_engine('mssql+pyodbc://TSMMHSQVS901/DV_BBG?driver=SQL+Server+Native+Client+11.0?trusted_connection=yes')\n",
      "p_if_exists='fail'\n",
      "if p_mode=='r':\n",
      "    p_if_exists='replace'\n",
      "if p_mode=='a':\n",
      "    p_if_exists='append'\n",
      "f = open(file_mdd,'r', encoding=\"UTF-8\")\n",
      "filedata = f.read()\n",
      "f.close()\n",
      "filecontent=filedata.replace('/Arc 3/2000-02-04','/Arc_3/2000_02_04')\n",
      "filecontent=filecontent.replace('encoding=\"UTF-8\"','')\n",
      "tree = etree.fromstring(filecontent)\n",
      "list_variables=tree.findall('.//definition/variable')\n",
      "list_categories=tree.findall('.//definition/categories')\n",
      "list_fields=tree.findall('.//design/fields')\n",
      "type(list_categories[0])\n",
      "list_fields[0].attrib\n",
      "dfid = pd.DataFrame()\n",
      "for field in list_fields:\n",
      "    #for variable in field.getchildren():\n",
      "    for variable in field.iter(\"variable\"):\n",
      "        #print(variable.attrib['id'],variable.attrib['name'])\n",
      "        dfid = dfid.append(pd.Series([variable.attrib['id'].replace('_',''),variable.attrib['name'],'variable']),ignore_index=True)\n",
      "    for loop in field.iter(\"loop\"):\n",
      "        for class_ in loop.iter(\"class\"):\n",
      "            for fields in class_.iter(\"fields\"):\n",
      "                for variable in fields.iter(\"variable\"):\n",
      "        #print(loop.attrib['id'],loop.attrib['name'])\n",
      "                    dfid = dfid.append(pd.Series([variable.attrib['id'].replace('_',''),loop.attrib['name'],'loop']),ignore_index=True)\n",
      "dfid.columns=['id','name','type']\n",
      "dfid.to_csv(file_id_out_csv,sep='\\t',index=False)\n",
      "try:\n",
      "    dfid[:0].to_sql(p_out_sql_id,engine_dv_bbg, if_exists=p_if_exists, index=False)\n",
      "except ValueError:\n",
      "    pass\n",
      "\n",
      "#dfBTS[dfdb.columns].to_csv(p_out_csv_L1_BTS_country,sep='\\t',index=False)\n",
      "p = Popen([file_bat,p_out_sql_id,p_out_sql_id+'.csv'], cwd=path_bat)\n",
      "stdout, stderr = p.communicate()\n",
      "df = pd.DataFrame()\n",
      "for variable in list_variables:\n",
      "    for categories in variable.getchildren():\n",
      "        for category in categories.iter(\"category\"):\n",
      "            for labels in category.iter(\"labels\"):\n",
      "                for element in labels.iter(\"text\"):\n",
      "                    if element.attrib['{http://www.w3.org/XML/1998/namespace}lang']=='de-DE':\n",
      "                        #print(variable.attrib['name'],category.attrib['name'], element.text)\n",
      "                        df = df.append(pd.Series([variable.attrib['id'].replace('_',''),category.attrib['id'],variable.attrib['name'],category.attrib['name'], element.text]),ignore_index=True)\n",
      "df.columns=['DimID','ID','DimVar',  'DimVal','Label']\n",
      "dfx = pd.DataFrame()\n",
      "for categories_ in list_categories:\n",
      "#    for categories_ in categories_.getchildren():\n",
      "    for category in categories_.iter(\"category\"):\n",
      "        for labels in category.iter(\"labels\"):\n",
      "            for element in labels.iter(\"text\"):\n",
      "                if element.attrib['{http://www.w3.org/XML/1998/namespace}lang']=='de-DE':\n",
      "                    #print(variable.attrib['name'],category.attrib['name'], element.text)\n",
      "                    dfx = dfx.append(pd.Series([variable.attrib['id'].replace('_',''),category.attrib['id'],categories_.attrib['name'],category.attrib['name'], element.text]),ignore_index=True)\n",
      "dfx.columns=['DimID','ID','DimVar',  'DimVal','Label']\n",
      "#df[['DimVar','DimVal','Label']].to_csv(file_answer_out_csv,sep='\\t',index=False)\n",
      "dfx.to_csv(file_lists_out_csv,sep='\\t',index=False)\n",
      "try:\n",
      "    dfx[:0].to_sql(p_out_sql_lists,engine_dv_bbg, if_exists=p_if_exists, index=False)\n",
      "except ValueError:\n",
      "    pass\n",
      "\n",
      "#dfBTS[dfdb.columns].to_csv(p_out_csv_L1_BTS_country,sep='\\t',index=False)\n",
      "p = Popen([file_bat,p_out_sql_lists,p_out_sql_lists+'.csv'], cwd=path_bat)\n",
      "stdout, stderr = p.communicate()\n",
      "#print(df[['DimVar','DimVal','Label']].to_string())\n",
      "#df[['DimVar','DimVal','Label']].to_csv(file_answer_out_csv,sep='\\t',index=False)\n",
      "df.to_csv(file_answer_out_csv,sep='\\t',index=False)\n",
      "try:\n",
      "    df[:0].to_sql(p_out_sql_answer,engine_dv_bbg, if_exists=p_if_exists, index=False)\n",
      "except ValueError:\n",
      "    pass\n",
      "\n",
      "#dfBTS[dfdb.columns].to_csv(p_out_csv_L1_BTS_country,sep='\\t',index=False)\n",
      "p = Popen([file_bat,p_out_sql_answer,p_out_sql_answer+'.csv'], cwd=path_bat)\n",
      "stdout, stderr = p.communicate()\n",
      "list_categoryids=tree.findall('.//categorymap/categoryid')\n",
      "\n",
      "dfcat = pd.DataFrame()\n",
      "for categoryid in list_categoryids:\n",
      "    dfcat = dfcat.append(pd.Series([categoryid.attrib['value'],categoryid.attrib['name']]),ignore_index=True)\n",
      "dfcat.columns=['CatValue','CatName']\n",
      "dfcat.CatValue=dfcat.CatValue.astype(int)\n",
      "\n",
      "varcode=re.compile('^(_[0-9]{1,7})$')\n",
      "dfcat['Code']=dfcat.CatName.str.extract(varcode, expand=True)[0].str[1:].fillna(-1).astype(int)\n",
      "varcode=re.compile('(.*?)(_[0-9]{1,7})(.*?)')\n",
      "dfcat['Code2']=dfcat.CatName.str.extract(varcode, expand=True)[1].str[1:].fillna(-1).astype(int)\n",
      "\n",
      "dict_mdd=dict(zip(dfcat['CatValue'].astype(int),dfcat['CatName']))\n",
      "dfcat.to_csv(file_cat_out_csv,sep='\\t',index=False)\n",
      "try:\n",
      "    dfcat[:0].to_sql(p_out_sql_cat,engine_dv_bbg, if_exists=p_if_exists, index=False)\n",
      "except ValueError:\n",
      "    pass\n",
      "\n",
      "#dfBTS[dfdb.columns].to_csv(p_out_csv_L1_BTS_country,sep='\\t',index=False)\n",
      "p = Popen([file_bat,p_out_sql_cat,p_out_sql_cat+'.csv'], cwd=path_bat)\n",
      "stdout, stderr = p.communicate()\n"
     ]
    }
   ],
   "source": [
    "# extract\n",
    "notebook_loc = path + 'nb_1122.ipynb'\n",
    "def get_text(path):\n",
    "    with open(notebook_loc) as fp:\n",
    "        test = nbformat.read(fp, nbformat.NO_CONVERT)\n",
    "    cells = test['cells']\n",
    "    code_cells = [c for c in cells if c['cell_type'] == 'code' or c['cell_type'] == 'markdown']\n",
    "    for cell in code_cells:\n",
    "        print(cell['source'])\n",
    "\n",
    "get_text(path)\n",
    "\n",
    "# to elastic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "path = './sample_data/data/notebooks/'\n",
    "filenames = os.listdir()\n",
    "print(len(filenames))\n",
    "# ids = filenames\n",
    "# link\n",
    "# text\n",
    "# code/markdown splitten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'README.md', 'path': 'README.md', 'sha': '3a2ef147dc181623006c1838518320be6db31ae9', 'size': 859, 'url': 'https://api.github.com/repos/mwaskom/nipype_concepts/contents/README.md?ref=master', 'html_url': 'https://github.com/mwaskom/nipype_concepts/blob/master/README.md', 'git_url': 'https://api.github.com/repos/mwaskom/nipype_concepts/git/blobs/3a2ef147dc181623006c1838518320be6db31ae9', 'download_url': 'https://raw.githubusercontent.com/mwaskom/nipype_concepts/master/README.md', 'type': 'file', 'content': 'TmlweXBlIENvbmNlcHRzCj09PT09PT09PT09PT09PQoKVGhpcyBjb2xsZWN0\\naW9uIG9mIFtJUHl0aG9uXShodHRwOi8vaXB5dGhvbi5vcmcvKQpub3RlYm9v\\na3Mgc2hvdWxkIHByb3ZpZGUgYW4gaW50cm9kdWN0aW9uIHRvIHNvbWUgb2Yg\\ndGhlIAptYWluIGNvbmNlcHRzIGNlbnRyYWwgdG8gdXNpbmcgW05pcHlwZV0o\\naHR0cDovL25pcHkuc291cmNlZm9yZ2UubmV0L25pcHlwZS8pCmZvciBuZXVy\\nb2ltYWdpbmcgYW5hbHlzaXMuIAoKU3RhdGljIEhUTUwgTGlua3MKLS0tLS0t\\nLS0tLS0tLS0tLS0KCi0gW0ludGVyZmFjZXNdKGh0dHA6Ly9uYnZpZXdlci5p\\ncHl0aG9uLm9yZy91cmxzL3Jhdy5naXRodWIuY29tL213YXNrb20vbmlweXBl\\nX2NvbmNlcHRzL21hc3Rlci9pbnRlcmZhY2VzLmlweW5iKQotIFtXb3JrZmxv\\nd3NdKGh0dHA6Ly9uYnZpZXdlci5pcHl0aG9uLm9yZy91cmxzL3Jhdy5naXRo\\ndWIuY29tL213YXNrb20vbmlweXBlX2NvbmNlcHRzL21hc3Rlci93b3JrZmxv\\nd3MuaXB5bmIpCi0gW0l0ZXJhdGlvbl0oaHR0cDovL25idmlld2VyLmlweXRo\\nb24ub3JnL3VybHMvcmF3LmdpdGh1Yi5jb20vbXdhc2tvbS9uaXB5cGVfY29u\\nY2VwdHMvbWFzdGVyL2l0ZXJhdGlvbi5pcHluYikKClJlcXVpcmVtZW50cwot\\nLS0tLS0tLS0tLS0KCi0gW0lQeXRob25dKGh0dHA6Ly9pcHl0aG9uLm9yZy8p\\nCi0gW05pcHlwZV0oaHR0cDovL25pcHkuc291cmNlZm9yZ2UubmV0L25pcHlw\\nZS8pCi0gW0ZTTF0oaHR0cDovL2ZzbC5mbXJpYi5veC5hYy51ay9mc2wvZnNs\\nd2lraS8pCi0gW1NQTV0oaHR0cDovL3d3dy5maWwuaW9uLnVjbC5hYy51ay9z\\ncG0vKSAoT3B0aW9uYWwpCgpMaWNlbnNlCi0tLS0tLS0KClNpbXBsaWZpZWQg\\nQlNECg==\\n', 'encoding': 'base64', '_links': {'self': 'https://api.github.com/repos/mwaskom/nipype_concepts/contents/README.md?ref=master', 'git': 'https://api.github.com/repos/mwaskom/nipype_concepts/git/blobs/3a2ef147dc181623006c1838518320be6db31ae9', 'html': 'https://github.com/mwaskom/nipype_concepts/blob/master/README.md'}}\n"
     ]
    }
   ],
   "source": [
    "path = './sample_data/data/readmes/readme_4045820.json'\n",
    "with open(path) as json_file:\n",
    "    data = json.load(json_file)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 2 column 1 (char 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-1ebf65ef95f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnotebook_loc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mO:\\Anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[0mcls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m         parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mO:\\Anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 354\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mO:\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m         \"\"\"\n\u001b[1;32m--> 339\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mO:\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 2 column 1 (char 1)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
